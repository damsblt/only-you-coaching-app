#!/usr/bin/env node
/**
 * Script pour identifier les vidÃ©os qui avaient des doublons par URL
 * Analyse les patterns pour trouver les URLs qui pourraient avoir Ã©tÃ© dupliquÃ©es
 */

import dotenv from 'dotenv'
import { fileURLToPath } from 'url'
import { dirname, join } from 'path'
import { neon } from '@neondatabase/serverless'

const __filename = fileURLToPath(import.meta.url)
const __dirname = dirname(__filename)

dotenv.config({ path: join(__dirname, '..', '.env.local') })

const sql = neon(process.env.DATABASE_URL)

async function identifyDuplicateUrls() {
  console.log('ğŸ” Identification des vidÃ©os qui avaient des doublons par URL\n')
  console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n')
  
  try {
    // Le script de nettoyage a trouvÃ© 4 URLs avec doublons et supprimÃ© 16 doublons
    // Cela signifie qu'il y avait probablement 4-5 vidÃ©os par URL
    
    // Cherchons les vidÃ©os qui ont des patterns similaires qui pourraient indiquer
    // qu'elles Ã©taient des doublons (mÃªme URL mais encodage diffÃ©rent, etc.)
    
    // 1. Chercher les vidÃ©os avec des URLs trÃ¨s similaires (mÃªme chemin mais encodage diffÃ©rent)
    console.log('ğŸ“Š Analyse des URLs similaires...\n')
    
    const similarUrls = await sql`
      WITH url_parts AS (
        SELECT 
          id,
          title,
          "videoUrl",
          region,
          "videoNumber",
          "createdAt",
          -- Extraire le chemin sans l'encodage
          REGEXP_REPLACE("videoUrl", '%[0-9A-F]{2}', '', 'g') as url_normalized
        FROM videos_new
        WHERE "videoType" = 'MUSCLE_GROUPS'
        AND "videoUrl" IS NOT NULL
      )
      SELECT 
        url_normalized,
        COUNT(*) as count,
        ARRAY_AGG(title ORDER BY "createdAt" DESC) as titles,
        ARRAY_AGG("videoUrl" ORDER BY "createdAt" DESC) as urls,
        ARRAY_AGG(region ORDER BY "createdAt" DESC) as regions,
        ARRAY_AGG("videoNumber" ORDER BY "createdAt" DESC) as numbers
      FROM url_parts
      GROUP BY url_normalized
      HAVING COUNT(*) > 1
      ORDER BY count DESC
      LIMIT 10
    `
    
    if (similarUrls.length > 0) {
      console.log(`   âš ï¸  ${similarUrls.length} groupes d'URLs similaires trouvÃ©s\n`)
      similarUrls.forEach((group, i) => {
        console.log(`\n${i + 1}. Groupe avec ${group.count} URLs similaires:`)
        console.log(`   Chemin normalisÃ©: ${group.url_normalized.substring(0, 100)}...`)
        console.log(`   Titres: ${group.titles.slice(0, 3).join(', ')}`)
        console.log(`   RÃ©gions: ${group.regions.join(', ')}`)
        console.log(`   Numbers: ${group.numbers.filter(n => n !== null).join(', ')}`)
      })
    } else {
      console.log('   âœ… Aucun groupe d\'URLs similaires trouvÃ©\n')
    }
    
    // 2. Chercher les vidÃ©os crÃ©Ã©es exactement au mÃªme moment (probablement des doublons)
    console.log('\nğŸ“Š Analyse des vidÃ©os crÃ©Ã©es au mÃªme moment...\n')
    
    const sameTimeVideos = await sql`
      SELECT 
        DATE_TRUNC('second', "createdAt") as created_second,
        COUNT(*) as count,
        ARRAY_AGG(title ORDER BY id) as titles,
        ARRAY_AGG("videoUrl" ORDER BY id) as urls,
        ARRAY_AGG(region ORDER BY id) as regions
      FROM videos_new
      WHERE "videoType" = 'MUSCLE_GROUPS'
      AND "createdAt" >= NOW() - INTERVAL '2 days'
      GROUP BY DATE_TRUNC('second', "createdAt")
      HAVING COUNT(*) >= 4
      ORDER BY count DESC, created_second DESC
      LIMIT 10
    `
    
    if (sameTimeVideos.length > 0) {
      console.log(`   âš ï¸  ${sameTimeVideos.length} groupes de vidÃ©os crÃ©Ã©es au mÃªme moment\n`)
      sameTimeVideos.forEach((group, i) => {
        console.log(`\n${i + 1}. ${group.count} vidÃ©os crÃ©Ã©es Ã  ${group.created_second}:`)
        console.log(`   Titres: ${group.titles.slice(0, 5).join(', ')}`)
        if (group.titles.length > 5) {
          console.log(`   ... et ${group.titles.length - 5} autres`)
        }
      })
    } else {
      console.log('   âœ… Aucun groupe de vidÃ©os crÃ©Ã©es au mÃªme moment trouvÃ©\n')
    }
    
    // 3. Conclusion
    console.log('\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n')
    console.log('ğŸ’¡ Note: Les 4 URLs avec doublons ont Ã©tÃ© nettoyÃ©es.')
    console.log('   Le script a supprimÃ© 16 doublons (probablement 4-5 vidÃ©os par URL).')
    console.log('   Les vidÃ©os restantes sont les versions les plus rÃ©centes.\n')
    
  } catch (error) {
    console.error('âŒ Erreur:', error.message)
    if (error.stack) {
      console.error(error.stack)
    }
    process.exit(1)
  }
}

identifyDuplicateUrls().catch(error => {
  console.error('âŒ Erreur:', error)
  process.exit(1)
})
